{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Pricing Model: Ridge Regression with Hyperparameter Tuning and MLflow Tracking\n",
    "\n",
    "This notebook demonstrates a complete machine learning workflow for a dynamic pricing problem, including feature selection, hyperparameter tuning using `GridSearchCV` on a **Ridge Regression** model, and meticulous logging of all parameters, metrics, and the final model using **MLflow**.\n",
    "\n",
    "**Prerequisites:** This notebook assumes you have the required libraries installed (`pandas`, `numpy`, `sklearn`, `mlflow`, `matplotlib`) and that the data file `9e05bb74-2719-45b0-bbc7-0ced2f61a442_dynamicpricingmodelingprepareddata.csv` is available in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Configuration and Setup ---\n",
    "\n",
    "# Define the file path for the uploaded data\n",
    "FILE_NAME = \"9e05bb74-2719-45b0-bbc7-0ced2f61a442_dynamicpricingmodelingprepareddata.csv\"\n",
    "TARGET = 'LogSellingPrice'\n",
    "EXPERIMENT_NAME = \"Dynamic_Pricing_Model_Ridge_Tuning\"\n",
    "\n",
    "# Define the features to be used in the model\n",
    "FEATURE_COLS = [\n",
    "    'UnitsSold', 'StockStart', 'Demand', 'Backorders', 'StockEnd',\n",
    "    'ReorderPoint', 'OrderPlaced', 'OrderQty', 'LeadTimeFloat', 'SafetyStock',\n",
    "    'CTR', 'AbandonedCartRate', 'BounceRate', 'FunnelDrop_ViewToCart',\n",
    "    'FunnelDrop_CartToCheckout', 'ReturningVisitorRatio', 'AvgSessionDuration_sec',\n",
    "    'DiscountRate_Nirma', 'DiscountRate_Surf Excel', 'FinalPrice_Nirma', 'FinalPrice_Surf Excel'\n",
    "]\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# --- 1. Data Preparation ---\n",
    "\n",
    "def load_and_split_data(file_name, features, target):\n",
    "    \"\"\"Loads data, selects features, and splits into train/test sets.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(file_name)\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    # Use 80% for training and 20% for testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Data split: Training size={len(X_train)}, Testing size={len(X_test)}\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Load and split the data\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(FILE_NAME, FEATURE_COLS, TARGET)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluation Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "helpers"
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_test, y_pred, X_test):\n",
    "    \"\"\"Calculates all required regression metrics.\"\"\"\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Adjusted R-squared calculation\n",
    "    n = X_test.shape[0] # number of samples\n",
    "    k = X_test.shape[1] # number of features\n",
    "    # Check for valid denominator to prevent errors\n",
    "    if (n - k - 1) <= 0:\n",
    "        adj_r2 = -float('inf')\n",
    "    else:\n",
    "        adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'mse': mse,\n",
    "        'adj_r2': adj_r2\n",
    "    }\n",
    "\n",
    "def create_residual_plot(y_test, y_pred, plot_path=\"residual_plot.png\"):\n",
    "    \"\"\"Generates a residual plot and saves it as a PNG file.\"\"\"\n",
    "    residuals = y_test - y_pred\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.scatter(y_pred, residuals, alpha=0.6)\n",
    "    ax.hlines(0, y_pred.min(), y_pred.max(), color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel(\"Predicted Log Selling Price\", fontsize=12)\n",
    "    ax.set_ylabel(\"Residuals (Actual - Predicted)\", fontsize=12)\n",
    "    ax.set_title(\"Residual Plot: Assessing Model Bias\", fontsize=14)\n",
    "    ax.grid(True, linestyle=':', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close(fig)\n",
    "    return plot_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning and MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "main_training_function"
    ]
   },
   "outputs": [],
   "source": [
    "def train_and_log_model(X_train, X_test, y_train, y_test, features):\n",
    "    \"\"\"\n",
    "    Performs Grid Search hyperparameter tuning for Ridge Regression,\n",
    "    logs each candidate run, and logs the final best model.\n",
    "    \"\"\"\n",
    "    print(f\"Starting experiment: {EXPERIMENT_NAME}\")\n",
    "\n",
    "    # Model definition: Ridge Regression\n",
    "    ridge_model = Ridge(random_state=42)\n",
    "\n",
    "    # Hyperparameter search space for alpha\n",
    "    param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "    # Set up GridSearchCV for cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=ridge_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='r2',\n",
    "        cv=3, \n",
    "        n_jobs=-1, \n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    print(\"Beginning Grid Search for best 'alpha' parameter...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # --- Extract Best Model Details ---\n",
    "    best_alpha = grid_search.best_params_['alpha']\n",
    "    best_score = grid_search.best_score_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict with the best model on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_metrics = calculate_metrics(y_test, y_pred, X_test)\n",
    "\n",
    "    # --- Start the FINAL Run for the BEST Model ---\n",
    "    with mlflow.start_run(run_name=f\"Ridge_Best_Alpha={best_alpha}\") as run:\n",
    "        print(f\"\\nLogging BEST model run: {run.info.run_id}\")\n",
    "\n",
    "        # Log Model Parameters\n",
    "        mlflow.log_param(\"model_type\", \"Ridge Regression (Regularized Linear Model)\")\n",
    "        mlflow.log_param(\"best_alpha\", best_alpha)\n",
    "        mlflow.log_param(\"cv_best_score_r2\", f\"{best_score:.4f}\")\n",
    "        mlflow.log_param(\"feature_count\", len(features))\n",
    "        mlflow.log_param(\"target_variable\", TARGET)\n",
    "        \n",
    "        feature_engineering = (\n",
    "            \"No scaling applied; feature selection based on numerical non-date columns.\"\n",
    "        )\n",
    "        mlflow.log_param(\"feature_engineering_details\", feature_engineering)\n",
    "        mlflow.log_param(\"features_list\", features)\n",
    "\n",
    "        # Log Evaluation Metrics\n",
    "        mlflow.log_metrics(test_metrics)\n",
    "        print(f\"Logged Test Set RMSE: {test_metrics['rmse']:.4f}\")\n",
    "        print(f\"Logged Test Set Adjusted R2: {test_metrics['adj_r2']:.4f}\")\n",
    "\n",
    "        # Create and Log Artifact (Residual Plot)\n",
    "        plot_path = create_residual_plot(y_test, y_pred)\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        print(f\"Logged artifact: {plot_path}\")\n",
    "        \n",
    "        # Define and Log Input-Output Signature\n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "        # Log the Final Trained Model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"ridge_model\", \n",
    "            signature=signature,\n",
    "            input_example=X_test.head(1).to_dict() \n",
    "        )\n",
    "        print(\"Logged final Ridge model with signature and input example.\")\n",
    "        \n",
    "    return run.info.run_id\n",
    "\n",
    "# --- Execution ---\n",
    "final_run_id = train_and_log_model(X_train, X_test, y_train, y_test, FEATURE_COLS)\n",
    "print(\"\\n-------------------------------------------------\")\n",
    "print(\"MLflow Execution Summary\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Final Best Run ID: {final_run_id}\")\n",
    "print(\"All parameters, metrics, the model, and a residual plot have been logged.\")\n",
    "print(\"View the results in the MLflow UI by navigating to this Run ID.\")\n",
    "print(\"-------------------------------------------------\")\n",
    "# Clean up temporary plot file\n",
    "if os.path.exists(\"residual_plot.png\"):\n",
    "    os.remove(\"residual_plot.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
